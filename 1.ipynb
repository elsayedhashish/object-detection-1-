{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a775742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Path: c:\\Users\\CLICK\\OneDrive\\Desktop\\CV\\yolo 2\\venv\\Scripts\\python.exe\n",
      "all libraries are installed ✅\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "  \n",
    "print(\"Python Path:\", sys.executable)\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    print(\"all libraries are installed ✅\")\n",
    "except ImportError:\n",
    "    print(\"there is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "# download the model that i trained\n",
    "model = YOLO('best (3).pt') \n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "look_away_start = 0\n",
    "\n",
    "# for full screen display\n",
    "window_name = 'Absolute Gaze Detection'\n",
    "cv2.namedWindow(window_name, cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    # activate YOLO detection on the current frame\n",
    "    yolo_results = model(frame, conf=0.2, iou=0.5, verbose=False)\n",
    "    for r in yolo_results:\n",
    "        for box in r.boxes:\n",
    "            label = model.names[int(box.cls[0])].lower()\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            # detect if the detected object is a phone, earphone, or paper and draw a red rectangle with a warning text\n",
    "            if any(x in label for x in [ 'phone', 'earphone', 'paper']):\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "                cv2.putText(frame, f\"!!! {label.upper()} !!!\", (x1, y1-10), 1, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Face Mesh for gaze detection \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mesh_results = face_mesh.process(rgb_frame)\n",
    "    gaze_direction = \"Forward\"\n",
    "\n",
    "    if mesh_results.multi_face_landmarks:\n",
    "        for face_landmarks in mesh_results.multi_face_landmarks:\n",
    "            nose = face_landmarks.landmark[1]\n",
    "            forehead = face_landmarks.landmark[10]\n",
    "            chin = face_landmarks.landmark[152]\n",
    "            \n",
    "            #حسابات بؤبؤ العين اليسرى\n",
    "            left_iris = face_landmarks.landmark[468]\n",
    "            l_inner = face_landmarks.landmark[133]\n",
    "            l_outer = face_landmarks.landmark[33]\n",
    "            \n",
    "            # النسبة الأفقية (h_ratio)\n",
    "            h_ratio = (left_iris.x - l_outer.x) / (l_inner.x - l_outer.x)\n",
    "\n",
    "            # حسابات الميل الرأسي (Head Pitch)\n",
    "            face_height = chin.y - forehead.y\n",
    "            nose_relative_pos = (nose.y - forehead.y) / face_height\n",
    " \n",
    "            if h_ratio > 0.65 or nose.x > 0.65: \n",
    "                gaze_direction = \"Looking Left\"\n",
    "            elif h_ratio < 0.35 or nose.x < 0.35: \n",
    "                gaze_direction = \"Looking Right\"\n",
    "            elif nose_relative_pos < 0.42: \n",
    "                gaze_direction = \"Looking Up\"\n",
    "            elif nose_relative_pos > 0.65: \n",
    "                gaze_direction = \"Looking Down\"\n",
    "\n",
    "            # العرض على الشاشة\n",
    "            color = (0, 255, 0) if gaze_direction == \"Forward\" else (0, 0, 255)\n",
    "            cv2.putText(frame, f\"GAZE: {gaze_direction}\", (20, 50), 1, 2, color, 3)\n",
    "            \n",
    "            # منطق الـ Violation\n",
    "            if gaze_direction != \"Forward\":\n",
    "                if look_away_start == 0: look_away_start = time.time()\n",
    "                if time.time() - look_away_start > 1.5:\n",
    "                    cv2.putText(frame, \"!!! GAZE VIOLATION !!!\", (20, 110), 1, 2, (0,0,255), 3)\n",
    "            else:\n",
    "                look_away_start = 0\n",
    "\n",
    "    #  للعرض علي الشاشه كامله \n",
    "    cv2.imshow(window_name, frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec16d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1c4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
